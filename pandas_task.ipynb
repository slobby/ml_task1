{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to complete this assignment\n",
    "First, download [this Kaggle dataset](https://www.kaggle.com/hugomathien/soccer) and extract *sqlite* database. You may need to register at https://www.kaggle.com/ beforehand. Then complete 15 graded tasks below, the score is given in brackets. Finally submit the resulting `.ipynb` file to rs-app Auto-test.\n",
    "\n",
    "- Do not delete or rename the variables given before the inscription `#your code here`, they are needed for the correct verification.\n",
    "- Do not change the code in the last Notebook cell, it is required for the server check.\n",
    "- Your Notebook must run completely without errors to be graded! Please check everything before submission by going *Cell -> Run All*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some important notes\n",
    "- If you need to **calculate the number of \"something\"** that means we expect you to assign an Integer to the given variable\n",
    "- If you need to **make a list of \"something\"** we expect you to assign a Python list with appropriate values to the given variable\n",
    "- If you need to find a **specifi—Å player, day of the week, team, etc.** we expect you to assign a String with the full name of the entity to the given variable (`player_name`, day of week full name, `team_name`, etc.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_column', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "# Leave that code unchanged, it is required for the server check!\n",
    "db = sqlite3.connect(os.environ.get(\"DB_PATH\") or 'database.sqlite')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "# You may load the data from SQL table directly to the Pandas dataframe as\n",
    "player_data = pd.read_sql(\"SELECT * FROM Player;\", db)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "player_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_api_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_fifa_api_id</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>505942</td>\n",
       "      <td>Aaron Appindangoye</td>\n",
       "      <td>218353</td>\n",
       "      <td>1992-02-29 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>155782</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>189615</td>\n",
       "      <td>1989-12-15 00:00:00</td>\n",
       "      <td>170.18</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>162549</td>\n",
       "      <td>Aaron Doran</td>\n",
       "      <td>186170</td>\n",
       "      <td>1991-05-13 00:00:00</td>\n",
       "      <td>170.18</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30572</td>\n",
       "      <td>Aaron Galindo</td>\n",
       "      <td>140161</td>\n",
       "      <td>1982-05-08 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23780</td>\n",
       "      <td>Aaron Hughes</td>\n",
       "      <td>17725</td>\n",
       "      <td>1979-11-08 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  player_api_id         player_name  player_fifa_api_id  \\\n",
       "0   1         505942  Aaron Appindangoye              218353   \n",
       "1   2         155782     Aaron Cresswell              189615   \n",
       "2   3         162549         Aaron Doran              186170   \n",
       "3   4          30572       Aaron Galindo              140161   \n",
       "4   5          23780        Aaron Hughes               17725   \n",
       "\n",
       "              birthday  height  weight  \n",
       "0  1992-02-29 00:00:00  182.88     187  \n",
       "1  1989-12-15 00:00:00  170.18     146  \n",
       "2  1991-05-13 00:00:00  170.18     163  \n",
       "3  1982-05-08 00:00:00  182.88     198  \n",
       "4  1979-11-08 00:00:00  182.88     154  "
      ]
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 1 (0.25 point).** Calculate the number of players with a height between 180 and 190 inclusive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "source": [
    "players_180_190 = player_data['height'].between(180,190).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 2 (0.25 point).** Calculate the number of players born in 1980. <br>\n",
    "**Hint:** you may want to cast your 'birthday' column to DateTime type by [pandas.to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "players_1980 = (pd.to_datetime(player_data['birthday']).dt.year == 1980).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 3 (0.25 point).** Make a list of the top 10 players with the highest weight sorted in descending order. If there are several players with the same weight put them in the lexicographic order by name."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "highest_players = player_data.sort_values(['weight', 'player_name'], ascending=(False, True))['player_name'].head(10).to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 4 (0.5 point).** Make a list of tuples containing years along with the number of players born in that year from 1980 up to 1990. <br>\n",
    "**Structure example**: [(1980, 123), (1981, 140) ..., (1990, 83)] -> There were born 123 players in 1980, there were born 140 players in 1981 and etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "player_data1 = player_data\n",
    "player_data1['year'] = pd.to_datetime(player_data['birthday']).dt.year\n",
    "player_year_series = player_data1[player_data1['year'].between(1980,1990)].groupby('year').size()\n",
    "years_born_players = list(zip(player_year_series.index, player_year_series))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 5 (0.5 point).** Calculate the mean and the standard deviation of the players' **height** with the name **Adriano**. <br>\n",
    "**Note:** Name is represented by the first part of `player_name`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "adriano_mean, adriano_std = player_data[player_data['player_name'].str.startswith('Adriano')]['height'].agg(['mean', 'std']).values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 6 (0.75 point).** How many players were born on each day of the week? Find the day of the week with the minimum number of players born."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "player_data2 = player_data\n",
    "player_data2['day_of_birth'] = pd.to_datetime(player_data['birthday']).dt.day_name()\n",
    "dow_with_min_players_born = player_data2.groupby('day_of_birth').size().idxmin()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 7 (0.75 point).** Find a league with the most matches in total. If there are several leagues with the same amount of matches, take the first in the lexical order."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "match_data = pd.read_sql(\"SELECT * FROM Match;\", db)\n",
    "league_data = pd.read_sql(\"SELECT * FROM League;\", db)\n",
    "dfg = match_data.groupby('league_id', as_index=False, sort=False).size()\n",
    "max_matches = dfg['size'].max()\n",
    "mdfg = dfg[dfg['size'] == max_matches]\n",
    "mdfg1 = mdfg.rename(columns={'league_id':'id'})\n",
    "\n",
    "league_most_matches = pd.merge(league_data, mdfg1).sort_values('name').iloc[0]['name']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 8 (1.25 point).** Find a player who participated in the largest number of matches during the whole match history. Assign a `player_name` to the given variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "home_player = 'home_player_'\n",
    "away_player = 'away_player_'\n",
    "home_players = [item+str(index) for index, item in enumerate(list([home_player]*11), start=1)]\n",
    "away_players = [item+str(index) for index,\n",
    "                item in enumerate(list([away_player]*11), start=1)]\n",
    "players = home_players + away_players\n",
    "# match_data.dtypes\n",
    "ps = [match_data[item].dropna().astype('int64') for item in players]\n",
    "most_freq = pd.concat(ps).mode()\n",
    "max_matches_player = player_data[player_data['player_api_id'] ==\n",
    "int(most_freq)].iloc[0]['player_name']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "player_attributes_data = pd.read_sql(\"SELECT * FROM Player_Attributes;\", db)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 9 (1.5 point).** List top-5 tuples of most correlated **player's characteristics** in the descending order of the absolute [Pearson's coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) value.\n",
    "\n",
    "**Note 1:** Players characteristics are all the columns in `Player_Attributes` table except `[id, player_fifa_api_id, player_api_id, date, preferred_foot, attacking_work_rate, defensive_work_rate]`). <br>\n",
    "**Note 2:** Exclude duplicated pairs from the list. E.g. ('gk_handling', 'gk_reflexes') and ('gk_reflexes', 'gk_handling') are duplicates, leave just one of them in the resulting list.\n",
    "\n",
    "**Hint:** You may use [dataframe.corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) for calculating pairwise Pearson correlation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "pure_player_attributes_data = player_attributes_data.drop(columns=['id', 'player_fifa_api_id', 'player_api_id', 'date', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate'])\n",
    "cor_df = pure_player_attributes_data.corr().abs()\n",
    "cor_df = cor_df.unstack().reset_index()\n",
    "cor_df.columns = ['character_1', 'character_2', 'correlation']\n",
    "mask_dups = (cor_df[['character_1', 'character_2']].apply(frozenset, axis=1).duplicated()) | (cor_df['character_1']==cor_df['character_2']) \n",
    "cor_df = cor_df[~mask_dups]\n",
    "sorted_cor_df = cor_df.sort_values(by=['correlation'], ascending=False)\n",
    "cor_df_top_5 = sorted_cor_df.reset_index()[['character_1', 'character_2']].iloc[:5]\n",
    "cor_df_top_5\n",
    "# top_correlated_features = list(cor_df_top_5.itertuples(index=False, name=None))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_1</th>\n",
       "      <th>character_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gk_positioning</td>\n",
       "      <td>gk_reflexes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gk_handling</td>\n",
       "      <td>gk_reflexes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gk_handling</td>\n",
       "      <td>gk_positioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standing_tackle</td>\n",
       "      <td>sliding_tackle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marking</td>\n",
       "      <td>standing_tackle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character_1      character_2\n",
       "0   gk_positioning      gk_reflexes\n",
       "1      gk_handling      gk_reflexes\n",
       "2      gk_handling   gk_positioning\n",
       "3  standing_tackle   sliding_tackle\n",
       "4          marking  standing_tackle"
      ]
     },
     "metadata": {},
     "execution_count": 250
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 10 (2 points).** Find top-5 most similar players to **Neymar** whose names are given. The similarity is measured as [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between vectors of players' characteristics (described in the task above). Put their names in a vector in ascending order by Euclidean distance and sorted by `player_name` if the distance is the same<br>\n",
    "**Note 1:** There are many records for some players in the `Player_Attributes` table. You need to take the freshest data (characteristics with the most recent `date`). <br>\n",
    "**Note 2:** Use pure values of the characteristics even if you are aware of such preprocessing technics as normalization. <br>\n",
    "**Note 3:** Please avoid using any built-in methods for calculating the Euclidean distance between vectors, think about implementing your own."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "source": [
    "characters_list = ['gk_positioning', 'gk_reflexes', 'gk_handling', 'standing_tackle', 'sliding_tackle', 'marking' ]\n",
    "player_attributes_data_cast = player_attributes_data[['player_api_id', 'date'] + characters_list]\n",
    "player_attributes_data_cast['date'] = pd.to_datetime(player_attributes_data_cast['date'])\n",
    "\n",
    "neymar_id = player_data.loc[(player_data['player_name'].str.startswith('Neymar'))].reset_index().at[0,'player_api_id']\n",
    "\n",
    "fresh_payer_id_data = player_attributes_data_cast.groupby(by='player_api_id')['date'].agg(['max']).reset_index()\n",
    "neymar_fresh_data = fresh_payer_id_data[fresh_payer_id_data['player_api_id']==neymar_id].iat[0, 1]\n",
    "neymar_characteristics = player_attributes_data_cast[(player_attributes_data_cast['player_api_id'] == neymar_id) & (player_attributes_data_cast['date'] == neymar_fresh_data)]\n",
    "fresh_payer_id_data = fresh_payer_id_data.drop(fresh_payer_id_data[fresh_payer_id_data['player_api_id'] == neymar_id].index)\n",
    "for  player_id, fresh_date in fresh_payer_id_data.itertuples(index=False, name=None):\n",
    "    player_attributes_data_cast.loc[(player_attributes_data_cast['player_api_id'] == player_id) & (player_attributes_data_cast['date'] == fresh_date)]\n",
    "    \n",
    "# player_attributes_data_cast[player_attributes_data_cast['player_api_id'] == neymar_id]\n",
    "# neymar_similarities = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\slobbery.GBAS\\AppData\\Local\\Temp\\ipykernel_216\\3017346041.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  player_attributes_data_cast['date'] = pd.to_datetime(player_attributes_data_cast['date'])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [298]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m fresh_payer_id_data \u001b[38;5;241m=\u001b[39m fresh_payer_id_data\u001b[38;5;241m.\u001b[39mdrop(fresh_payer_id_data[fresh_payer_id_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_api_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m neymar_id]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m  player_id, fresh_date \u001b[38;5;129;01min\u001b[39;00m fresh_payer_id_data\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 12\u001b[0m     player_attributes_data_cast\u001b[38;5;241m.\u001b[39mloc[(player_attributes_data_cast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_api_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m player_id) \u001b[38;5;241m&\u001b[39m (\u001b[43mplayer_attributes_data_cast\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfresh_date\u001b[49m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:269\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    262\u001b[0m         )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    265\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    267\u001b[0m ):\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1028\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1025\u001b[0m result \u001b[38;5;241m=\u001b[39m op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), other_vals\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1027\u001b[0m o_mask \u001b[38;5;241m=\u001b[39m isna(other)\n\u001b[1;32m-> 1028\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_isnan\u001b[49m \u001b[38;5;241m|\u001b[39m o_mask\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   1030\u001b[0m     nat_result \u001b[38;5;241m=\u001b[39m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:841\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._isnan\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;129m@property\u001b[39m  \u001b[38;5;66;03m# NB: override with cache_readonly in immutable subclasses\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isnan\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_]:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m    return if each value is nan\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masi8\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miNaT\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "team_data = pd.read_sql(\"SELECT * FROM Team;\", db)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 11 (1 point).** Calculate the number of home matches played by the **Borussia Dortmund** team in **Germany 1. Bundesliga** in season **2008/2009**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "borussia_id = team_data.loc[(team_data['team_long_name'] == 'Borussia Dortmund')].reset_index().at[0,'team_api_id']\n",
    "g1_bundesliga_id = league_data.loc[(league_data['name'] == 'Germany 1. Bundesliga')].reset_index().at[0,'id']\n",
    "season = '2008/2009'\n",
    "borussia_bundesliga_2008_2009_matches = len(match_data[(match_data['league_id']==g1_bundesliga_id) & (match_data['season']==season) & (match_data['home_team_api_id']==borussia_id)])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 12 (1 point).** Find a team having the most matches (both home and away!) in the **Germany 1. Bundesliga** in **2008/2009** season. Return number of matches."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "source": [
    "g1_bundesliga_season = match_data[(match_data['league_id']==g1_bundesliga_id) & (match_data['season']==season)]\n",
    "home_teams = g1_bundesliga_season['home_team_api_id'].value_counts()\n",
    "away_teams = g1_bundesliga_season['away_team_api_id'].value_counts()\n",
    "team_most_matches_bundesliga_2008_2009 = home_teams.add(away_teams, fill_value=0).sort_values().iloc[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 13 (1 point).** Count total number of **Arsenal** matches (both home and away!) in the **2015/2016** season which they have won. <br><br>\n",
    "**Note:** Winning a game means scoring **more** goals than an opponent."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "source": [
    "season_2015 = '2015/2016'\n",
    "arsenal_id = team_data.loc[(team_data['team_long_name'] == 'Arsenal')].reset_index(drop=True).at[0,'team_api_id']\n",
    "arsenal_won_matches = match_data[(match_data['season']==season_2015) & (((match_data['home_team_api_id']==arsenal_id) & (match_data['home_team_goal'] > match_data['away_team_goal'])) | ((match_data['away_team_api_id']==arsenal_id) & (match_data['away_team_goal'] > match_data['home_team_goal'])))]\n",
    "arsenal_won_matches_2015_2016 = len(arsenal_won_matches)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 14 (2 points).** Find a team with the highest win rate in the **2015/2016** season. Win rate means won matches / all matches. If there are several teams with the highest win rate return the first by name in lexical order"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "matches_2015 = match_data[match_data['season']==season_2015]\n",
    "matches_2015_home = matches_2015[['home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal']]\n",
    "matches_2015_away = matches_2015_home.copy()\n",
    "matches_2015_home1 = matches_2015_home.rename(columns={'home_team_api_id':'team_api_id', 'away_team_api_id':'alient_team_api_id', 'home_team_goal':'team_goal','away_team_goal':'alient_team_goal' })\n",
    "matches_2015_away1 = matches_2015_away.rename(columns={'away_team_api_id':'team_api_id', 'home_team_api_id':'alient_team_api_id', 'away_team_goal':'team_goal','home_team_goal':'alient_team_goal' })\n",
    "whole_matches = pd.concat([matches_2015_home1, matches_2015_away1])\n",
    "whole_matches['winner'] = whole_matches.apply(lambda x: 1 if x['team_goal'] > x['alient_team_goal'] else 0, axis=1)\n",
    "winner_df = whole_matches.groupby('team_api_id')['winner'].agg(['sum','count'])\n",
    "winner_df['rate'] = winner_df.apply(lambda x: x['sum']/x['count'], axis=1)\n",
    "team_highest_winrate_2015_2016 = winner_df.sort_values(by='rate', ascending=False).merge(team_data, on='team_api_id').at[0, 'team_long_name']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 15 (2 points).** Determine the team with the maximum days' gap between matches in **England Premier League 2010/2011 season**. Return number of days in that gap. <br>\n",
    "**Note**: a *gap* means the number of days between two consecutive matches of the same team."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "season_2010 = '2010/2011'\n",
    "en_league_id = league_data.loc[(league_data['name'] == 'England Premier League')].reset_index().at[0,'id']\n",
    "en_league_id\n",
    "# highest_gap_england_2010_2011 = 0"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1729"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Warning! Do not change anything in the area below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "with open('student_answers.txt', 'w') as file:\n",
    "    file.write(f\"{players_180_190}\\n\")\n",
    "    file.write(f\"{players_1980}\\n\")\n",
    "    file.write(f\"{highest_players}\\n\")\n",
    "    file.write(f\"{years_born_players}\\n\")\n",
    "    file.write(f\"{round(adriano_mean, 3)} {round(adriano_std, 3)}\\n\")\n",
    "    file.write(f\"{dow_with_min_players_born}\\n\")\n",
    "    file.write(f\"{league_most_matches}\\n\")\n",
    "    file.write(f\"{max_matches_player}\\n\")\n",
    "    file.write(f\"{';'.join(['%s,%s' % tup for tup in top_correlated_features])};\\n\")\n",
    "    file.write(f\"{neymar_similarities}\\n\")\n",
    "    file.write(f\"{borussia_bundesliga_2008_2009_matches}\\n\")\n",
    "    file.write(f\"{team_most_matches_bundesliga_2008_2009}\\n\")\n",
    "    file.write(f\"{arsenal_won_matches_2015_2016}\\n\")\n",
    "    file.write(f\"{team_highest_winrate_2015_2016}\\n\")\n",
    "    file.write(f\"{highest_gap_england_2010_2011}\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26dc3c06508c5583e2f848078e1ab346729e72da36f4849c4f922a5647a9f703"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}